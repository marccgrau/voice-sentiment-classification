{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id               prolific_id  \\\n",
      "0  0944b194-9e71-4ab5-9438-c7ab3f326c9d  65cd505d9ba7450b9be3d6f7   \n",
      "1  db01fe1c-30ac-422d-b4f9-81e5f2532d11  65cd505d9ba7450b9be3d6f7   \n",
      "2  8da13785-e98e-4a20-a5a7-fe604a5d9a1b  65cd505d9ba7450b9be3d6f7   \n",
      "3  0a7c3bf1-be52-4d2a-ad66-fb6137da25c7  65cd505d9ba7450b9be3d6f7   \n",
      "4  98bf782a-a675-4b2e-afe8-5977b311be3e  65cd505d9ba7450b9be3d6f7   \n",
      "\n",
      "                             snippet_id  aggression  frustration  annoyance  \\\n",
      "0  0e60f04a-575f-41a6-8449-6d8b3d1fab6f           3            7          7   \n",
      "1  06a012e5-95c2-4ec8-9435-693b851a995b           2            8          7   \n",
      "2  43081c99-a9ba-4b0a-8f8e-73a443409de4           1            1          1   \n",
      "3  7d9a30f9-b288-4a6d-a3d4-302c4910c403           1            1          1   \n",
      "4  e5633971-506b-4fc7-9fd2-99b848bdc0be           1            3          4   \n",
      "\n",
      "                   created_at  \n",
      "0  2025-03-18 14:54:42.046667  \n",
      "1  2025-03-18 14:54:54.357149  \n",
      "2  2025-03-18 14:55:04.378355  \n",
      "3   2025-03-18 14:55:19.22917  \n",
      "4   2025-03-18 14:55:29.33083  \n",
      "                                     id                       file_path  \\\n",
      "0  c5cc04d3-93da-4b19-9fc8-8dd6cb966aa4  actor1_call_10_sentence_11.wav   \n",
      "1  238d0941-40cc-4b80-847d-709d96dd5ca3  actor1_call_15_sentence_22.wav   \n",
      "2  f7c3cd3e-a45e-4c86-a9ed-51fe6e784158  actor1_call_11_sentence_13.wav   \n",
      "3  24f33c60-9d45-4d20-a4a5-779998a17ed9   actor1_call_13_sentence_4.wav   \n",
      "4  6ea84adc-784a-4d1a-892d-4e23d7d10726    actor1_call_1_sentence_7.wav   \n",
      "\n",
      "   rating_count                  created_at  \\\n",
      "0             8  2025-03-17 14:33:18.289288   \n",
      "1             8  2025-03-17 14:33:24.357225   \n",
      "2             8  2025-03-17 14:33:20.221241   \n",
      "3             8   2025-03-17 14:33:22.22707   \n",
      "4             8   2025-03-17 14:33:25.93312   \n",
      "\n",
      "                                          public_url  \n",
      "0  https://axjrcyouittmkkwtkswr.supabase.co/stora...  \n",
      "1  https://axjrcyouittmkkwtkswr.supabase.co/stora...  \n",
      "2  https://axjrcyouittmkkwtkswr.supabase.co/stora...  \n",
      "3  https://axjrcyouittmkkwtkswr.supabase.co/stora...  \n",
      "4  https://axjrcyouittmkkwtkswr.supabase.co/stora...  \n",
      "Initial lengths: 4274 1098\n",
      "After dropping null snippet_id: 3882\n",
      "After dropping duplicates: 3831\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 1: Load and clean the data\n",
    "# ---------------------------\n",
    "ratings_df = pd.read_csv(\"raw_data/ratings_v2.csv\")\n",
    "audio_snippets_df = pd.read_csv(\"raw_data/audio_snippets_v2.csv\")\n",
    "attention_check_fails = pd.read_csv(\"raw_data/attention_checks_v2.csv\")\n",
    "\n",
    "# Display heads and lengths (for debugging purposes)\n",
    "print(ratings_df.head())\n",
    "print(audio_snippets_df.head())\n",
    "print(\"Initial lengths:\", len(ratings_df), len(audio_snippets_df))\n",
    "\n",
    "# Drop rows where snippet_id is null\n",
    "ratings_df = ratings_df.dropna(subset=[\"snippet_id\"])\n",
    "print(\"After dropping null snippet_id:\", len(ratings_df))\n",
    "\n",
    "# Drop duplicate ratings for the same snippet and prolific_id\n",
    "ratings_df = ratings_df.drop_duplicates(subset=[\"snippet_id\", \"prolific_id\"])\n",
    "print(\"After dropping duplicates:\", len(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ratings_df before dropping failed users: 3831\n",
      "Length of ratings_df after dropping failed users: 3786\n"
     ]
    }
   ],
   "source": [
    "# Drop all ratings of users that failed the attention check\n",
    "failed_users = attention_check_fails[attention_check_fails[\"failed\"] == True][\"user_id\"]\n",
    "print(\"Length of ratings_df before dropping failed users:\", len(ratings_df))\n",
    "ratings_df = ratings_df[~ratings_df[\"prolific_id\"].isin(failed_users)]\n",
    "print(\"Length of ratings_df after dropping failed users:\", len(ratings_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snippet-level statistics:\n",
      "                             snippet_id  aggression_mean  aggression_std  \\\n",
      "0  0016c3f7-2a20-4664-bc0e-0a4625a0c782         2.000000        0.816497   \n",
      "1  00453e9c-ad07-4fc9-8598-3595da3595bc         1.333333        0.577350   \n",
      "2  007bd96e-e95b-461d-bb6b-897cad86f8e7         2.000000        2.000000   \n",
      "3  008c9118-f8a0-4e0e-86fd-285568bdb3d8         6.000000        2.828427   \n",
      "4  0093ef4f-f12c-458a-8ffb-284a465efa4e         5.666667        2.081666   \n",
      "\n",
      "   aggression_count  frustration_mean  frustration_std  frustration_count  \\\n",
      "0                 4          4.000000         2.160247                  4   \n",
      "1                 3          2.333333         2.309401                  3   \n",
      "2                 4          1.250000         0.500000                  4   \n",
      "3                 4          6.750000         1.500000                  4   \n",
      "4                 3          4.666667         1.527525                  3   \n",
      "\n",
      "   annoyance_mean  annoyance_std  annoyance_count  aggression_agreement  \\\n",
      "0        4.500000       2.380476                4              0.871700   \n",
      "1        2.000000       1.000000                3              0.909278   \n",
      "2        1.000000       0.000000                4              0.685730   \n",
      "3        9.250000       0.957427                4              0.555556   \n",
      "4        5.666667       2.516611                3              0.672898   \n",
      "\n",
      "   frustration_agreement  annoyance_agreement  \n",
      "0               0.660550             0.625944  \n",
      "1               0.637113             0.842865  \n",
      "2               0.921433             1.000000  \n",
      "3               0.764298             0.849555  \n",
      "4               0.759973             0.604553  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 2: Compute per-snippet statistics and normalized agreement\n",
    "# ---------------------------\n",
    "emotions = [\"aggression\", \"frustration\", \"annoyance\"]\n",
    "\n",
    "# Calculate mean, standard deviation, and count for each emotion by snippet\n",
    "agg_functions = {emotion: [\"mean\", \"std\", \"count\"] for emotion in emotions}\n",
    "snippet_stats = ratings_df.groupby(\"snippet_id\").agg(agg_functions)\n",
    "\n",
    "# Flatten MultiIndex column names (e.g., \"aggression_mean\", \"aggression_std\", \"aggression_count\")\n",
    "snippet_stats.columns = [\"_\".join(col).strip() for col in snippet_stats.columns.values]\n",
    "snippet_stats.reset_index(inplace=True)\n",
    "\n",
    "# For the normalized agreement, assume ratings range from 1 to 10.\n",
    "min_rating, max_rating = 1, 10\n",
    "max_std = np.std([min_rating, max_rating], ddof=1)  # worst-case disagreement\n",
    "\n",
    "# Compute normalized agreement for each emotion (1 = perfect, 0 = worst)\n",
    "for emotion in emotions:\n",
    "    std_col = f\"{emotion}_std\"\n",
    "    agreement_col = f\"{emotion}_agreement\"\n",
    "    # If std is NaN (e.g. only one rating), the agreement will be left as NaN.\n",
    "    snippet_stats[agreement_col] = 1 - (snippet_stats[std_col] / max_std)\n",
    "\n",
    "# (Optional) View the snippet-level stats\n",
    "print(\"Snippet-level statistics:\")\n",
    "print(snippet_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 3: Define a function to drop the lowest 10% based on agreement\n",
    "# ---------------------------\n",
    "def drop_low_agreement(df, emotion, percentile=10):\n",
    "    \"\"\"\n",
    "    Drops the lowest <percentile>% of snippets based on the normalized agreement for the given emotion.\n",
    "\n",
    "    Parameters:\n",
    "      df: DataFrame that contains snippet-level stats including the '{emotion}_agreement' column.\n",
    "      emotion: The emotion for which to filter (e.g., 'aggression').\n",
    "      percentile: The cutoff percentile (default is 10, meaning drop bottom 10%).\n",
    "\n",
    "    Returns:\n",
    "      Filtered DataFrame with only snippets above the cutoff.\n",
    "    \"\"\"\n",
    "    agreement_col = f\"{emotion}_agreement\"\n",
    "    # Calculate the cutoff value (lowest 10% agreement)\n",
    "    cutoff = np.percentile(df[agreement_col].dropna(), percentile)\n",
    "    # Keep only snippets with agreement above the cutoff\n",
    "    filtered_df = df[df[agreement_col] > cutoff].copy()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggression ratings to ratings/aggression_ratings.csv\n",
      "Saved frustration ratings to ratings/frustration_ratings.csv\n",
      "Saved annoyance ratings to ratings/annoyance_ratings.csv\n",
      "\n",
      "Emotion: aggression\n",
      "979\n",
      "                        file_path    rating\n",
      "0   actor1_call_10_sentence_9.wav  2.000000\n",
      "1   actor2_call_32_sentence_3.wav  1.333333\n",
      "2   actor4_call_22_sentence_2.wav  2.000000\n",
      "3   actor4_call_25_sentence_7.wav  6.000000\n",
      "4  actor3_call_40_sentence_13.wav  5.666667\n",
      "\n",
      "Emotion: frustration\n",
      "979\n",
      "                        file_path    rating\n",
      "0   actor1_call_10_sentence_9.wav  4.000000\n",
      "1   actor2_call_32_sentence_3.wav  2.333333\n",
      "2   actor4_call_22_sentence_2.wav  1.250000\n",
      "3   actor4_call_25_sentence_7.wav  6.750000\n",
      "4  actor3_call_40_sentence_13.wav  4.666667\n",
      "\n",
      "Emotion: annoyance\n",
      "979\n",
      "                        file_path    rating\n",
      "0   actor1_call_10_sentence_9.wav  4.500000\n",
      "1   actor2_call_32_sentence_3.wav  2.000000\n",
      "2   actor4_call_22_sentence_2.wav  1.000000\n",
      "3   actor4_call_25_sentence_7.wav  9.250000\n",
      "4  actor3_call_40_sentence_13.wav  5.666667\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 4: Create individual emotion DataFrames, merge with audio snippets, and store results\n",
    "# ---------------------------\n",
    "emotion_dfs = {}\n",
    "for emotion in emotions:\n",
    "    # Filter out snippets with very low agreement for this emotion\n",
    "    filtered_stats = drop_low_agreement(snippet_stats.copy(), emotion, percentile=10)\n",
    "\n",
    "    # Create a temporary DataFrame with snippet_id, mean rating, and agreement for this emotion\n",
    "    temp_df = filtered_stats[\n",
    "        [\"snippet_id\", f\"{emotion}_mean\", f\"{emotion}_agreement\"]\n",
    "    ].copy()\n",
    "    temp_df.rename(\n",
    "        columns={f\"{emotion}_mean\": \"rating\", f\"{emotion}_agreement\": \"agreement\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # Merge with the audio snippets DataFrame.\n",
    "    # Note: ratings_df uses 'snippet_id' and audio_snippets_df uses 'id' for the snippet identifier.\n",
    "    merged_df = pd.merge(\n",
    "        temp_df, audio_snippets_df, left_on=\"snippet_id\", right_on=\"id\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Retain only the file_path from audio_snippets and the average rating.\n",
    "    final_df = merged_df[[\"file_path\", \"rating\"]].copy()\n",
    "    emotion_dfs[emotion] = final_df\n",
    "\n",
    "    # Save the final DataFrame for this emotion to a CSV file.\n",
    "    output_filename = f\"ratings/{emotion}_ratings.csv\"\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved {emotion} ratings to {output_filename}\")\n",
    "\n",
    "# (Optional) Print a preview of the final DataFrames\n",
    "for emotion, df in emotion_dfs.items():\n",
    "    print(f\"\\nEmotion: {emotion}\")\n",
    "    print(len(df))\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggression binary ratings to ratings/aggression_binary_ratings.csv\n",
      "Saved frustration binary ratings to ratings/frustration_binary_ratings.csv\n",
      "Saved annoyance binary ratings to ratings/annoyance_binary_ratings.csv\n",
      "\n",
      "Preview of binary ratings for 'aggression':\n",
      "                        file_path  binary_rating\n",
      "0   actor1_call_10_sentence_9.wav              0\n",
      "1   actor2_call_32_sentence_3.wav              0\n",
      "2   actor4_call_22_sentence_2.wav              0\n",
      "3   actor4_call_25_sentence_7.wav              1\n",
      "4  actor3_call_40_sentence_13.wav              1\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 5: Create binary classification DataFrames per emotion\n",
    "# ---------------------------\n",
    "binary_emotion_dfs = {}\n",
    "for emotion, df in emotion_dfs.items():\n",
    "    # Create a copy and binarize the rating (ratings > 5 become 1, otherwise 0)\n",
    "    df_binary = df.copy()\n",
    "    df_binary[\"binary_rating\"] = (df_binary[\"rating\"] > 5).astype(int)\n",
    "    # Drop the original ordinal rating, keeping only file_path and binary_rating\n",
    "    df_binary = df_binary[[\"file_path\", \"binary_rating\"]]\n",
    "    binary_emotion_dfs[emotion] = df_binary\n",
    "\n",
    "    # Save the binary DataFrame for this emotion\n",
    "    binary_output_filename = f\"ratings/{emotion}_binary_ratings.csv\"\n",
    "    df_binary.to_csv(binary_output_filename, index=False)\n",
    "    print(f\"Saved {emotion} binary ratings to {binary_output_filename}\")\n",
    "\n",
    "# Optional: Preview the binary DataFrame for one emotion (e.g., aggression)\n",
    "print(\"\\nPreview of binary ratings for 'aggression':\")\n",
    "print(binary_emotion_dfs[\"aggression\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
